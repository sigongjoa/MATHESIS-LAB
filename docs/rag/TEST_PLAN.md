# RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ê³„íšì„œ

## ğŸ“‹ ëª©ì°¨
1. [í…ŒìŠ¤íŠ¸ ì „ëµ](#1-í…ŒìŠ¤íŠ¸-ì „ëµ)
2. [ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (pytest)](#2-ë‹¨ìœ„-í…ŒìŠ¤íŠ¸-pytest)
3. [í†µí•© í…ŒìŠ¤íŠ¸](#3-í†µí•©-í…ŒìŠ¤íŠ¸)
4. [E2E í…ŒìŠ¤íŠ¸](#4-e2e-í…ŒìŠ¤íŠ¸)
5. [ì„±ëŠ¥ í…ŒìŠ¤íŠ¸](#5-ì„±ëŠ¥-í…ŒìŠ¤íŠ¸)
6. [RAG í’ˆì§ˆ í…ŒìŠ¤íŠ¸](#6-rag-í’ˆì§ˆ-í…ŒìŠ¤íŠ¸)

---

## 1. í…ŒìŠ¤íŠ¸ ì „ëµ

### 1.1 í…ŒìŠ¤íŠ¸ í”¼ë¼ë¯¸ë“œ

```
        â•±â•²
       â•±E2Eâ•²         10% - ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤
      â•±â”€â”€â”€â”€â”€â”€â•²
     â•± í†µí•©   â•²       20% - ì»´í¬ë„ŒíŠ¸ ê°„ ìƒí˜¸ì‘ìš©
    â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
   â•±   ë‹¨ìœ„     â•²     70% - ê°œë³„ í•¨ìˆ˜/í´ë˜ìŠ¤
  â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•²
```

### 1.2 í…ŒìŠ¤íŠ¸ ë²”ìœ„

| ê³„ì¸µ | í…ŒìŠ¤íŠ¸ ìœ í˜• | ë„êµ¬ | ëª©í‘œ ì»¤ë²„ë¦¬ì§€ |
|------|-----------|------|-------------|
| **Backend** | ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | pytest | 80%+ |
| **Backend** | í†µí•© í…ŒìŠ¤íŠ¸ | pytest | 60%+ |
| **Frontend** | ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | Jest, React Testing Library | 70%+ |
| **E2E** | ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ | Playwright | í•µì‹¬ í”Œë¡œìš° 100% |
| **RAG** | í’ˆì§ˆ í…ŒìŠ¤íŠ¸ | Ragas, Custom | Golden Set 100% |

---

## 2. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (pytest)

### 2.1 Parser Service í…ŒìŠ¤íŠ¸

```python
# backend/tests/unit/test_parser_service.py

import pytest
from pathlib import Path
from backend.app.services.parser_service import ParserService, ParseError
from backend.app.services.parser_service import ParsedChunk

@pytest.fixture
def parser_service():
    """Parser ì„œë¹„ìŠ¤ í”½ìŠ¤ì²˜"""
    return ParserService()

@pytest.fixture
def sample_pdf_path():
    """ìƒ˜í”Œ PDF íŒŒì¼ ê²½ë¡œ"""
    return Path("tests/fixtures/sample_curriculum.pdf")

class TestParserService:
    """Parser Service ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""
    
    def test_parse_pdf_success(self, parser_service, sample_pdf_path):
        """PDF íŒŒì‹± ì„±ê³µ ì¼€ì´ìŠ¤"""
        # Given
        assert sample_pdf_path.exists()
        
        # When
        chunks = parser_service.parse_document(
            sample_pdf_path,
            document_type="curriculum"
        )
        
        # Then
        assert len(chunks) > 0
        assert all(isinstance(c, ParsedChunk) for c in chunks)
        assert all(c.content for c in chunks)
        assert all(c.metadata for c in chunks)
    
    def test_parse_pdf_with_achievement_code(self, parser_service, sample_pdf_path):
        """ì„±ì·¨ê¸°ì¤€ ì½”ë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        # When
        chunks = parser_service.parse_document(sample_pdf_path, "curriculum")
        
        # Then
        achievement_chunks = [
            c for c in chunks 
            if c.metadata.get("curriculum_code")
        ]
        assert len(achievement_chunks) > 0
        
        # ì„±ì·¨ê¸°ì¤€ ì½”ë“œ í˜•ì‹ ê²€ì¦
        for chunk in achievement_chunks:
            code = chunk.metadata["curriculum_code"]
            assert code.startswith("[")
            assert code.endswith("]")
            # ì˜ˆ: [9ìˆ˜01-01]
            import re
            assert re.match(r'\[\d+[ê°€-í£]+\d+-\d+\]', code)
    
    def test_parse_nonexistent_file(self, parser_service):
        """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨"""
        # Given
        fake_path = Path("nonexistent.pdf")
        
        # When/Then
        with pytest.raises(FileNotFoundError):
            parser_service.parse_document(fake_path, "curriculum")
    
    def test_extract_metadata_national(self, parser_service, sample_pdf_path):
        """êµ­ê°€ êµìœ¡ê³¼ì • ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        # When
        chunks = parser_service.parse_document(sample_pdf_path, "curriculum")
        
        # Then
        for chunk in chunks:
            metadata = chunk.metadata
            assert "policy_version" in metadata
            assert metadata["scope_type"] == "NATIONAL"
            assert "document_type" in metadata
    
    def test_validate_chunk_success(self, parser_service):
        """ì²­í¬ ê²€ì¦ ì„±ê³µ"""
        # Given
        valid_chunk = ParsedChunk(
            content="í…ŒìŠ¤íŠ¸ ë‚´ìš©",
            metadata={
                "policy_version": "2022ê°œì •",
                "scope_type": "NATIONAL",
                "document_type": "ì„±ì·¨ê¸°ì¤€"
            },
            page_number=1
        )
        
        # When/Then
        assert parser_service.validate_chunk(valid_chunk) is True
    
    def test_validate_chunk_missing_metadata(self, parser_service):
        """í•„ìˆ˜ ë©”íƒ€ë°ì´í„° ëˆ„ë½ ì‹œ ê²€ì¦ ì‹¤íŒ¨"""
        # Given
        invalid_chunk = ParsedChunk(
            content="í…ŒìŠ¤íŠ¸ ë‚´ìš©",
            metadata={
                "policy_version": "2022ê°œì •"
                # scope_type ëˆ„ë½
            }
        )
        
        # When/Then
        assert parser_service.validate_chunk(invalid_chunk) is False

@pytest.mark.asyncio
class TestParserServiceAsync:
    """ë¹„ë™ê¸° íŒŒì‹± í…ŒìŠ¤íŠ¸"""
    
    async def test_parse_document_async(self, parser_service, sample_pdf_path):
        """ë¹„ë™ê¸° íŒŒì‹±"""
        chunks = await parser_service.parse_document(
            sample_pdf_path,
            "curriculum"
        )
        assert len(chunks) > 0
```

### 2.2 RAG Service í…ŒìŠ¤íŠ¸ (LLM Mock)

```python
# backend/tests/unit/test_rag_service.py

import pytest
from unittest.mock import Mock, AsyncMock, patch
from backend.app.services.rag_service import RAGService, RAGQuery
from backend.app.services.vector_store import VectorStore, SearchResult

@pytest.fixture
def mock_vector_store():
    """Vector Store Mock"""
    mock = Mock(spec=VectorStore)
    mock.search = AsyncMock(return_value=[
        SearchResult(
            chunk_id="chunk_123",
            content="ìµœëŒ€ê³µì•½ìˆ˜ì™€ ìµœì†Œê³µë°°ìˆ˜ëŠ” ì•½ìˆ˜ì™€ ë°°ìˆ˜ë¥¼ ë‚˜ì—´í•˜ì—¬...",
            score=0.89,
            metadata={
                "policy_version": "2022ê°œì •",
                "curriculum_code": "[6ìˆ˜01-05]",
                "page_number": 42
            }
        )
    ])
    return mock

@pytest.fixture
def mock_llm_client():
    """LLM Client Mock"""
    mock = Mock()
    mock.generate = AsyncMock(return_value="ì•„ë‹™ë‹ˆë‹¤. ì†Œì¸ìˆ˜ë¶„í•´ë¡œ ë‹¤ë£¨ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return mock

@pytest.fixture
def rag_service(mock_vector_store, mock_llm_client, db_session):
    """RAG Service í”½ìŠ¤ì²˜"""
    return RAGService(
        vector_store=mock_vector_store,
        llm_client=mock_llm_client,
        db=db_session
    )

@pytest.mark.asyncio
class TestRAGService:
    """RAG Service ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""
    
    async def test_query_success(self, rag_service):
        """RAG ì§ˆì˜ ì„±ê³µ"""
        # Given
        request = RAGQuery(
            query="ìµœëŒ€ê³µì•½ìˆ˜ëŠ” ì†Œì¸ìˆ˜ë¶„í•´ë¡œ ë‹¤ë£¨ë‚˜ìš”?",
            filters={"policy_version": "2022ê°œì •"},
            top_k=5
        )
        
        # When
        response = await rag_service.query(request, user_id="user_123")
        
        # Then
        assert response.answer
        assert len(response.sources) > 0
        assert response.confidence > 0
        assert response.processing_time_ms > 0
        assert response.query_id
    
    async def test_query_with_filters(self, rag_service, mock_vector_store):
        """í•„í„°ë§ëœ ì§ˆì˜"""
        # Given
        request = RAGQuery(
            query="í…ŒìŠ¤íŠ¸",
            filters={
                "policy_version": "2022ê°œì •",
                "scope_type": "NATIONAL",
                "grade_level": "ì´ˆ5~6"
            }
        )
        
        # When
        await rag_service.query(request, user_id="user_123")
        
        # Then
        # Vector storeê°€ ì˜¬ë°”ë¥¸ í•„í„°ë¡œ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_vector_store.search.assert_called_once()
        call_args = mock_vector_store.search.call_args
        assert call_args[1]["filters"] == request.filters
    
    async def test_build_prompt_with_sources(self, rag_service):
        """í”„ë¡¬í”„íŠ¸ êµ¬ì„± í…ŒìŠ¤íŠ¸"""
        # Given
        query = "ìµœëŒ€ê³µì•½ìˆ˜ëŠ”?"
        sources = [
            SearchResult(
                chunk_id="chunk_1",
                content="ë‚´ìš© 1",
                score=0.9,
                metadata={}
            ),
            SearchResult(
                chunk_id="chunk_2",
                content="ë‚´ìš© 2",
                score=0.8,
                metadata={}
            )
        ]
        
        # When
        prompt = rag_service._build_prompt(query, sources)
        
        # Then
        assert "ìµœëŒ€ê³µì•½ìˆ˜ëŠ”?" in prompt
        assert "ë‚´ìš© 1" in prompt
        assert "ë‚´ìš© 2" in prompt
        assert "ê·¼ê±°" in prompt or "ì¶œì²˜" in prompt
    
    async def test_add_citations(self, rag_service):
        """ì¸ìš© ì¶”ê°€ í…ŒìŠ¤íŠ¸"""
        # Given
        answer = "ì•„ë‹™ë‹ˆë‹¤. ì†Œì¸ìˆ˜ë¶„í•´ë¡œ ë‹¤ë£¨ì§€ ì•ŠìŠµë‹ˆë‹¤."
        sources = [
            SearchResult(
                chunk_id="chunk_123",
                content="...",
                score=0.89,
                metadata={"page_number": 42}
            )
        ]
        
        # When
        answer_with_citations = rag_service._add_citations(answer, sources)
        
        # Then
        assert "<ì¶œì²˜:" in answer_with_citations or "chunk_123" in answer_with_citations
    
    async def test_query_timeout(self, rag_service, mock_vector_store):
        """íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬"""
        # Given
        import asyncio
        mock_vector_store.search = AsyncMock(
            side_effect=asyncio.TimeoutError()
        )
        request = RAGQuery(query="í…ŒìŠ¤íŠ¸")
        
        # When/Then
        with pytest.raises(asyncio.TimeoutError):
            await rag_service.query(request, user_id="user_123")
```

### 2.3 Vector Store í…ŒìŠ¤íŠ¸

```python
# backend/tests/unit/test_vector_store.py

import pytest
from backend.app.services.vector_store import VectorStore

@pytest.fixture
def vector_store():
    """Vector Store í”½ìŠ¤ì²˜ (í…ŒìŠ¤íŠ¸ìš© ì¸ë©”ëª¨ë¦¬)"""
    # ì‹¤ì œ Qdrant ëŒ€ì‹  Mock ì‚¬ìš©
    from unittest.mock import Mock
    mock_client = Mock()
    store = VectorStore(url="memory://", api_key=None)
    store.client = mock_client
    return store

class TestVectorStore:
    """Vector Store ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_upsert_chunk(self, vector_store):
        """ì²­í¬ ì‚½ì… í…ŒìŠ¤íŠ¸"""
        # Given
        chunk_id = "chunk_123"
        embedding = [0.1] * 3072
        metadata = {"policy_version": "2022ê°œì •"}
        content = "í…ŒìŠ¤íŠ¸ ë‚´ìš©"
        
        # When
        await vector_store.upsert(chunk_id, embedding, metadata, content)
        
        # Then
        vector_store.client.upsert.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_search_with_filters(self, vector_store):
        """í•„í„°ë§ëœ ê²€ìƒ‰"""
        # Given
        query_vector = [0.1] * 3072
        filters = {"policy_version": "2022ê°œì •"}
        
        # When
        results = await vector_store.search(query_vector, filters, top_k=5)
        
        # Then
        vector_store.client.search.assert_called_once()
        call_args = vector_store.client.search.call_args
        assert call_args[1]["query_filter"] is not None
```

---

## 3. í†µí•© í…ŒìŠ¤íŠ¸

### 3.1 End-to-End íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

```python
# backend/tests/integration/test_rag_pipeline.py

import pytest
from pathlib import Path
from backend.app.services.parser_service import ParserService
from backend.app.services.rag_service import RAGService, RAGQuery
from backend.app.services.vector_store import VectorStore

@pytest.mark.integration
@pytest.mark.asyncio
class TestRAGPipeline:
    """RAG ì „ì²´ íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    async def test_full_indexing_and_query_pipeline(
        self,
        parser_service,
        vector_store,
        rag_service,
        sample_pdf_path
    ):
        """ë¬¸ì„œ ì¸ë±ì‹± â†’ ì§ˆì˜ â†’ ì‘ë‹µ ì „ì²´ í”Œë¡œìš°"""
        # 1. ë¬¸ì„œ íŒŒì‹±
        chunks = await parser_service.parse_document(
            sample_pdf_path,
            "curriculum"
        )
        assert len(chunks) > 0
        
        # 2. ì„ë² ë”© ìƒì„± ë° ì¸ë±ì‹±
        for chunk in chunks:
            embedding = await embedding_service.embed(chunk.content)
            await vector_store.upsert(
                chunk.chunk_id,
                embedding,
                chunk.metadata,
                chunk.content
            )
        
        # 3. ì§ˆì˜ ì‹¤í–‰
        request = RAGQuery(
            query="ìµœëŒ€ê³µì•½ìˆ˜ëŠ” ì†Œì¸ìˆ˜ë¶„í•´ë¡œ ë‹¤ë£¨ë‚˜ìš”?",
            filters={"policy_version": "2022ê°œì •"}
        )
        response = await rag_service.query(request, user_id="test_user")
        
        # 4. ì‘ë‹µ ê²€ì¦
        assert response.answer
        assert len(response.sources) > 0
        assert response.confidence > 0
        
        # 5. ì¸ìš© ê²€ì¦
        assert "<ì¶œì²˜:" in response.answer
```

### 3.2 ë°ì´í„°ë² ì´ìŠ¤ í†µí•© í…ŒìŠ¤íŠ¸

```python
# backend/tests/integration/test_rag_repository.py

import pytest
from backend.app.models.rag_chunk import RAGChunk
from backend.app.repositories.rag_repository import RAGRepository

@pytest.mark.integration
class TestRAGRepository:
    """RAG Repository í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def test_create_and_retrieve_chunk(self, db_session):
        """ì²­í¬ ìƒì„± ë° ì¡°íšŒ"""
        # Given
        repo = RAGRepository(db_session)
        chunk_data = {
            "content": "í…ŒìŠ¤íŠ¸ ë‚´ìš©",
            "metadata": {"policy_version": "2022ê°œì •"},
            "document_id": "doc_123"
        }
        
        # When
        chunk = repo.create_chunk(chunk_data)
        db_session.commit()
        
        # Then
        retrieved = repo.get_chunk(chunk.chunk_id)
        assert retrieved is not None
        assert retrieved.content == "í…ŒìŠ¤íŠ¸ ë‚´ìš©"
    
    def test_query_chunks_by_metadata(self, db_session):
        """ë©”íƒ€ë°ì´í„°ë¡œ ì²­í¬ ì¡°íšŒ"""
        # Given
        repo = RAGRepository(db_session)
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±...
        
        # When
        chunks = repo.find_by_metadata({
            "policy_version": "2022ê°œì •",
            "scope_type": "NATIONAL"
        })
        
        # Then
        assert len(chunks) > 0
        assert all(
            c.metadata["policy_version"] == "2022ê°œì •"
            for c in chunks
        )
```

---

## 4. E2E í…ŒìŠ¤íŠ¸

### 4.1 Playwright E2E í…ŒìŠ¤íŠ¸

```typescript
// MATHESIS-LAB_FRONT/tests/e2e/rag-query.spec.ts

import { test, expect } from '@playwright/test';

test.describe('RAG Query Flow', () => {
  test.beforeEach(async ({ page }) => {
    // ë¡œê·¸ì¸
    await page.goto('http://localhost:3001');
    await page.fill('#email', 'test@example.com');
    await page.fill('#password', 'password');
    await page.click('#login-button');
    await expect(page).toHaveURL(/.*curriculum/);
  });

  test('ì‚¬ìš©ìê°€ RAG ì§ˆì˜ë¥¼ í•˜ê³  ë‹µë³€ì„ ë°›ëŠ”ë‹¤', async ({ page }) => {
    // Given: AI Assistant ì—´ê¸°
    await page.click('#ai-assistant-button');
    await expect(page.locator('#rag-chat-panel')).toBeVisible();

    // When: ì§ˆë¬¸ ì…ë ¥
    const query = 'ì´ˆë“±í•™êµ 5~6í•™ë…„ ìˆ˜í•™ì—ì„œ ìµœëŒ€ê³µì•½ìˆ˜ëŠ” ì†Œì¸ìˆ˜ë¶„í•´ë¡œ ë‹¤ë£¨ë‚˜ìš”?';
    await page.fill('#rag-query-input', query);
    await page.click('#rag-submit-button');

    // Then: ë‹µë³€ í‘œì‹œ ëŒ€ê¸°
    await expect(page.locator('#rag-answer')).toBeVisible({ timeout: 10000 });
    
    // ë‹µë³€ ë‚´ìš© ê²€ì¦
    const answer = await page.locator('#rag-answer').textContent();
    expect(answer).toContain('ì•„ë‹™ë‹ˆë‹¤');
    expect(answer).toContain('ì†Œì¸ìˆ˜ë¶„í•´');

    // ì¶œì²˜ í‘œì‹œ ê²€ì¦
    const sources = page.locator('.rag-source-item');
    await expect(sources).toHaveCount(expect.any(Number));
    
    // ì²« ë²ˆì§¸ ì¶œì²˜ í™•ì¸
    const firstSource = sources.first();
    await expect(firstSource).toContainText('ì¶œì²˜:');
    await expect(firstSource).toContainText('í˜ì´ì§€');
  });

  test('í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ì§ˆì˜í•œë‹¤', async ({ page }) => {
    // Given
    await page.click('#ai-assistant-button');
    await page.click('#rag-filter-button');

    // When: í•„í„° ì„¤ì •
    await page.selectOption('#filter-policy-version', '2022ê°œì •');
    await page.selectOption('#filter-grade-level', 'ì´ˆ5~6');
    await page.fill('#rag-query-input', 'ìµœëŒ€ê³µì•½ìˆ˜');
    await page.click('#rag-submit-button');

    // Then
    await expect(page.locator('#rag-answer')).toBeVisible();
    
    // ì¶œì²˜ì˜ ë©”íƒ€ë°ì´í„° í™•ì¸
    await page.click('.rag-source-item:first-child .source-metadata-toggle');
    await expect(page.locator('.source-metadata')).toContainText('2022ê°œì •');
    await expect(page.locator('.source-metadata')).toContainText('ì´ˆ5~6');
  });

  test('ë‹µë³€ì— í”¼ë“œë°±ì„ ì œê³µí•œë‹¤', async ({ page }) => {
    // Given: ì§ˆì˜ ë° ë‹µë³€ ë°›ê¸°
    await page.click('#ai-assistant-button');
    await page.fill('#rag-query-input', 'í…ŒìŠ¤íŠ¸ ì§ˆë¬¸');
    await page.click('#rag-submit-button');
    await expect(page.locator('#rag-answer')).toBeVisible();

    // When: í”¼ë“œë°± ì œê³µ
    await page.click('#feedback-helpful-button');
    await page.fill('#feedback-comment', 'ì •í™•í•œ ë‹µë³€ì´ì—ˆìŠµë‹ˆë‹¤');
    await page.click('#feedback-submit-button');

    // Then
    await expect(page.locator('#feedback-success-message')).toBeVisible();
    await expect(page.locator('#feedback-success-message')).toContainText('ê°ì‚¬í•©ë‹ˆë‹¤');
  });
});
```

### 4.2 ë¬¸ì„œ ì¸ë±ì‹± E2E í…ŒìŠ¤íŠ¸

```typescript
// MATHESIS-LAB_FRONT/tests/e2e/document-indexing.spec.ts

import { test, expect } from '@playwright/test';
import path from 'path';

test.describe('Document Indexing Flow', () => {
  test('ê´€ë¦¬ìê°€ ìƒˆ êµìœ¡ê³¼ì • ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì¸ë±ì‹±í•œë‹¤', async ({ page }) => {
    // Given: ê´€ë¦¬ì ë¡œê·¸ì¸
    await page.goto('http://localhost:3001/admin');
    await page.fill('#email', 'admin@example.com');
    await page.fill('#password', 'admin_password');
    await page.click('#login-button');

    // RAG ê´€ë¦¬ í˜ì´ì§€ë¡œ ì´ë™
    await page.click('#rag-management-menu');
    await expect(page).toHaveURL(/.*rag\/management/);

    // When: ë¬¸ì„œ ì—…ë¡œë“œ
    const filePath = path.join(__dirname, '../fixtures/sample_curriculum.pdf');
    await page.setInputFiles('#document-upload-input', filePath);
    
    // ë©”íƒ€ë°ì´í„° ì…ë ¥
    await page.selectOption('#document-type', 'curriculum');
    await page.selectOption('#policy-version', '2022ê°œì •');
    await page.selectOption('#scope-type', 'NATIONAL');
    
    // ì—…ë¡œë“œ ì‹œì‘
    await page.click('#upload-start-button');

    // Then: ì§„í–‰ ìƒíƒœ í‘œì‹œ
    await expect(page.locator('#indexing-progress-bar')).toBeVisible();
    
    // ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 2ë¶„)
    await expect(page.locator('#indexing-status')).toContainText('ì™„ë£Œ', { timeout: 120000 });
    
    // ì²­í¬ ìˆ˜ í™•ì¸
    const chunksCount = await page.locator('#chunks-count').textContent();
    expect(parseInt(chunksCount!)).toBeGreaterThan(0);
  });
});
```

---

## 5. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### 5.1 ë¶€í•˜ í…ŒìŠ¤íŠ¸ (Locust)

```python
# backend/tests/performance/locustfile.py

from locust import HttpUser, task, between
import json

class RAGUser(HttpUser):
    """RAG ì‹œìŠ¤í…œ ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
    wait_time = between(1, 3)
    
    def on_start(self):
        """í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œ ë¡œê·¸ì¸"""
        response = self.client.post("/api/v1/auth/login", json={
            "email": "test@example.com",
            "password": "password"
        })
        self.token = response.json()["access_token"]
        self.headers = {"Authorization": f"Bearer {self.token}"}
    
    @task(10)
    def query_rag(self):
        """RAG ì§ˆì˜ (ê°€ì¥ ë¹ˆë²ˆí•œ ì‘ì—…)"""
        self.client.post(
            "/api/v1/rag/query",
            headers=self.headers,
            json={
                "query": "ìµœëŒ€ê³µì•½ìˆ˜ëŠ” ì†Œì¸ìˆ˜ë¶„í•´ë¡œ ë‹¤ë£¨ë‚˜ìš”?",
                "filters": {"policy_version": "2022ê°œì •"},
                "top_k": 5
            },
            name="/rag/query"
        )
    
    @task(1)
    def search_chunks(self):
        """ì²­í¬ ê²€ìƒ‰"""
        self.client.get(
            "/api/v1/rag/search?query=ìµœëŒ€ê³µì•½ìˆ˜&top_k=5",
            headers=self.headers,
            name="/rag/search"
        )
```

**ì‹¤í–‰:**
```bash
locust -f backend/tests/performance/locustfile.py --host=http://localhost:8000
```

**ëª©í‘œ:**
- P95 ì‘ë‹µ ì‹œê°„: < 3ì´ˆ
- ë™ì‹œ ì‚¬ìš©ì: 100ëª…
- ì—ëŸ¬ìœ¨: < 1%

---

## 6. RAG í’ˆì§ˆ í…ŒìŠ¤íŠ¸

### 6.1 Golden Set í…ŒìŠ¤íŠ¸

```python
# backend/tests/quality/test_golden_set.py

import pytest
from backend.app.services.rag_service import RAGService, RAGQuery

# Golden Set ì •ì˜
GOLDEN_SET = [
    {
        "query": "ì´ˆë“±í•™êµ 5~6í•™ë…„ ìˆ˜í•™ì—ì„œ ìµœëŒ€ê³µì•½ìˆ˜ëŠ” ì†Œì¸ìˆ˜ë¶„í•´ë¡œ ë‹¤ë£¨ë‚˜ìš”?",
        "expected_answer_contains": ["ì•„ë‹™ë‹ˆë‹¤", "ì†Œì¸ìˆ˜ë¶„í•´", "ë‹¤ë£¨ì§€ ì•Š"],
        "expected_sources_min": 1,
        "filters": {"policy_version": "2022ê°œì •", "grade_level": "ì´ˆ5~6"},
        "min_confidence": 0.7
    },
    {
        "query": "ì¤‘í•™êµ 1~3í•™ë…„ì—ì„œ ì¼ì°¨í•¨ìˆ˜ì™€ ì¼ì°¨ë°©ì •ì‹ì˜ ê´€ê³„ëŠ”?",
        "expected_answer_contains": ["ì¼ì°¨í•¨ìˆ˜", "ì¼ì°¨ë°©ì •ì‹", "ê´€ê³„"],
        "expected_sources_min": 2,
        "filters": {"policy_version": "2022ê°œì •", "grade_level": "ì¤‘1~3"},
        "min_confidence": 0.7
    },
    # ... ë” ë§ì€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
]

@pytest.mark.quality
@pytest.mark.asyncio
class TestGoldenSet:
    """Golden Set í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.parametrize("test_case", GOLDEN_SET)
    async def test_golden_set_query(self, rag_service, test_case):
        """Golden Set ê° ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
        # Given
        request = RAGQuery(
            query=test_case["query"],
            filters=test_case.get("filters", {}),
            top_k=5
        )
        
        # When
        response = await rag_service.query(request, user_id="test_user")
        
        # Then
        # 1. ë‹µë³€ì— ê¸°ëŒ€ í‚¤ì›Œë“œ í¬í•¨ í™•ì¸
        for keyword in test_case["expected_answer_contains"]:
            assert keyword in response.answer, \
                f"Expected keyword '{keyword}' not found in answer"
        
        # 2. ìµœì†Œ ì¶œì²˜ ìˆ˜ í™•ì¸
        assert len(response.sources) >= test_case["expected_sources_min"], \
            f"Expected at least {test_case['expected_sources_min']} sources"
        
        # 3. ì‹ ë¢°ë„ í™•ì¸
        assert response.confidence >= test_case["min_confidence"], \
            f"Confidence {response.confidence} below threshold {test_case['min_confidence']}"
        
        # 4. ì¸ìš© í¬í•¨ í™•ì¸
        assert "<ì¶œì²˜:" in response.answer, "No citations found in answer"
```

### 6.2 Ragas í‰ê°€

```python
# backend/tests/quality/test_ragas_evaluation.py

import pytest
from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy, context_recall

@pytest.mark.quality
@pytest.mark.asyncio
async def test_ragas_evaluation(rag_service):
    """Ragasë¥¼ ì‚¬ìš©í•œ RAG í’ˆì§ˆ í‰ê°€"""
    # Given: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
    test_dataset = {
        "question": ["ìµœëŒ€ê³µì•½ìˆ˜ëŠ” ì†Œì¸ìˆ˜ë¶„í•´ë¡œ ë‹¤ë£¨ë‚˜ìš”?"],
        "answer": [],
        "contexts": [],
        "ground_truth": ["ì•„ë‹™ë‹ˆë‹¤. ì•½ìˆ˜ì™€ ë°°ìˆ˜ë¥¼ ë‚˜ì—´í•˜ì—¬ ì°¾ëŠ” ë°©ë²•ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤."]
    }
    
    # When: RAG ì§ˆì˜
    request = RAGQuery(query=test_dataset["question"][0])
    response = await rag_service.query(request, user_id="test_user")
    
    test_dataset["answer"].append(response.answer)
    test_dataset["contexts"].append([s.content for s in response.sources])
    
    # Then: Ragas í‰ê°€
    result = evaluate(
        test_dataset,
        metrics=[faithfulness, answer_relevancy, context_recall]
    )
    
    # í‰ê°€ ê¸°ì¤€
    assert result["faithfulness"] >= 0.8, "Faithfulness too low"
    assert result["answer_relevancy"] >= 0.7, "Answer relevancy too low"
    assert result["context_recall"] >= 0.7, "Context recall too low"
```

---

## 7. í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### 7.1 ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ë°±ì—”ë“œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
pytest backend/tests/unit -v --cov=backend/app --cov-report=html

# ë°±ì—”ë“œ í†µí•© í…ŒìŠ¤íŠ¸
pytest backend/tests/integration -v -m integration

# í’ˆì§ˆ í…ŒìŠ¤íŠ¸
pytest backend/tests/quality -v -m quality

# í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸
cd MATHESIS-LAB_FRONT
npm test

# E2E í…ŒìŠ¤íŠ¸
npx playwright test

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
locust -f backend/tests/performance/locustfile.py
```

### 7.2 CI/CD í†µí•©

```yaml
# .github/workflows/rag-tests.yml

name: RAG Tests

on: [push, pull_request]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio
      - name: Run unit tests
        run: pytest backend/tests/unit -v --cov=backend/app
      - name: Upload coverage
        uses: codecov/codecov-action@v2

  integration-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v2
      - name: Run integration tests
        run: pytest backend/tests/integration -v -m integration

  e2e-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Install Playwright
        run: npx playwright install --with-deps
      - name: Run E2E tests
        run: npx playwright test
```

---

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ì‘ì„±ì¼**: 2025-11-20  
**ì‘ì„±ì**: MATHESIS LAB ê°œë°œíŒ€
